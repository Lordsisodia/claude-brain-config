input {
  beats {
    port => 5044
  }
  
  tcp {
    port => 5000
    codec => json_lines
  }
  
  udp {
    port => 5000
    codec => json_lines
  }
  
  # OpenTelemetry logs
  http {
    port => 5001
    codec => json
    additional_codecs => {
      "application/x-protobuf" => "protobuf"
    }
  }
}

filter {
  # Parse AI agent logs
  if [service] == "ai-agent" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:agent_id}\] %{GREEDYDATA:log_message}" 
      }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    # Extract intelligence metrics if present
    if [log_message] =~ /intelligence_score/ {
      grok {
        match => { 
          "log_message" => "intelligence_score:(?<intelligence_score>[0-9.]+)" 
        }
      }
      mutate {
        convert => { "intelligence_score" => "float" }
      }
    }
    
    # Extract performance metrics
    if [log_message] =~ /response_time/ {
      grok {
        match => { 
          "log_message" => "response_time:(?<response_time>[0-9.]+)" 
        }
      }
      mutate {
        convert => { "response_time" => "float" }
      }
    }
    
    # Extract error information
    if [level] == "ERROR" {
      grok {
        match => { 
          "log_message" => "error:(?<error_type>\w+) message:(?<error_message>.*)" 
        }
      }
    }
  }
  
  # Parse anomaly detection logs
  if [service] == "anomaly-detector" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} Anomaly detected: agent=(?<agent_id>\w+) type=(?<anomaly_type>\w+) score=(?<anomaly_score>[0-9.]+)" 
      }
    }
    
    if [anomaly_score] {
      mutate {
        convert => { "anomaly_score" => "float" }
      }
    }
  }
  
  # Parse emergence detection logs
  if [service] == "emergence-detector" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} Emergence event: type=(?<emergence_type>\w+) magnitude=(?<emergence_magnitude>[0-9.]+) agents=(?<involved_agents>[0-9]+)" 
      }
    }
    
    if [emergence_magnitude] {
      mutate {
        convert => { "emergence_magnitude" => "float" }
      }
    }
    
    if [involved_agents] {
      mutate {
        convert => { "involved_agents" => "integer" }
      }
    }
  }
  
  # Parse autoscaler logs
  if [service] == "autoscaler" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} Scaling action: (?<scaling_action>\w+) resource=(?<resource_name>\w+) from=(?<current_instances>[0-9]+) to=(?<target_instances>[0-9]+)" 
      }
    }
    
    if [current_instances] {
      mutate {
        convert => { "current_instances" => "integer" }
      }
    }
    
    if [target_instances] {
      mutate {
        convert => { "target_instances" => "integer" }
      }
    }
  }
  
  # Add common fields
  mutate {
    add_field => { "[@metadata][beat]" => "ai-observability" }
    add_field => { "platform" => "ai-agents" }
  }
  
  # Geolocate IP addresses if present
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }
  
  # Remove sensitive information
  mutate {
    remove_field => [ "password", "secret", "token", "api_key" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ai-logs-%{+YYYY.MM.dd}"
    template_name => "ai-logs"
    template_pattern => "ai-logs-*"
    template => {
      "settings" => {
        "number_of_shards" => 3,
        "number_of_replicas" => 1,
        "index.refresh_interval" => "30s"
      },
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" },
          "agent_id" => { "type" => "keyword" },
          "service" => { "type" => "keyword" },
          "level" => { "type" => "keyword" },
          "message" => { "type" => "text" },
          "intelligence_score" => { "type" => "float" },
          "response_time" => { "type" => "float" },
          "anomaly_score" => { "type" => "float" },
          "anomaly_type" => { "type" => "keyword" },
          "emergence_type" => { "type" => "keyword" },
          "emergence_magnitude" => { "type" => "float" },
          "scaling_action" => { "type" => "keyword" },
          "resource_name" => { "type" => "keyword" },
          "current_instances" => { "type" => "integer" },
          "target_instances" => { "type" => "integer" },
          "geoip" => {
            "properties" => {
              "location" => { "type" => "geo_point" },
              "country_name" => { "type" => "keyword" },
              "city_name" => { "type" => "keyword" }
            }
          }
        }
      }
    }
  }
  
  # Send critical alerts to a separate index
  if [level] == "CRITICAL" or [anomaly_score] and [anomaly_score] > 0.8 {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ai-alerts-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output (remove in production)
  if [level] == "DEBUG" {
    stdout { 
      codec => rubydebug 
    }
  }
}